# Avance 7

## Introducción

Este avance aplica redes neuronales recurrentes Elman y Jordan para el pronóstico de cantidades vendidas en el dataset `Online-Retail.xlsx`, agrupadas por mes.

## Preparación de datos

```{r setup_datos, include=TRUE}
library(readxl)
library(dplyr)
library(lubridate)
library(RSNNS)

# Cargar los datos
data <- read_excel("Online-Retail.xlsx")

# Limpiar datos
data_clean <- data %>%
  filter(!is.na(InvoiceDate), !is.na(Quantity)) %>%
  filter(Quantity > 0)  # Eliminar devoluciones (cantidades negativas)

# Crear columna de mes y agregar datos
data_monthly <- data_clean %>%
  mutate(Month = floor_date(as.POSIXct(InvoiceDate), "month")) %>%
  group_by(Month) %>%
  summarise(
    Quantity = sum(Quantity, na.rm = TRUE),
    N_transactions = n()
  ) %>%
  arrange(Month)

# Mostrar resumen de datos
print("Resumen de datos mensuales:")
print(data_monthly)

# Crear serie como vector
y_vec <- as.numeric(data_monthly$Quantity)

# Crear matriz de lags
n_lags <- 3
lag_matrix <- embed(y_vec, n_lags + 1)

# Separar en inputs y outputs
outputs <- lag_matrix[, 1]
inputs <- lag_matrix[, -1]

# Normalizar los datos
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

denormalize <- function(x, original) {
  return(x * (max(original) - min(original)) + min(original))
}

inputs_norm <- normalize(inputs)
outputs_norm <- normalize(outputs)

# Preparar datos de entrenamiento (usar todos menos el último para entrenar)
n_train <- nrow(inputs_norm) - 1
train_idx <- 1:n_train

# Preparar matrices de entrenamiento
x_train <- inputs_norm[train_idx,]
y_train <- matrix(outputs_norm[train_idx], ncol=1)

# Verificar dimensiones
print("\nDimensiones de los datos:")
print(paste("Entrenamiento X:", nrow(x_train), "x", ncol(x_train)))
print(paste("Entrenamiento Y:", nrow(y_train), "x", ncol(y_train)))

# Preparar datos de prueba
x_test <- matrix(inputs_norm[-train_idx,], ncol=ncol(inputs_norm))
y_test <- matrix(outputs_norm[-train_idx], ncol=1)
```

## Red Neuronal Elman

```{r elman-model}
# Entrenamiento del modelo Elman
fit_elman <- elman(x = x_train, 
                   y = y_train,
                   size = c(3),
                   learnFuncParams = c(0.1),
                   maxit = 500)

# Mostrar error de entrenamiento
plotIterativeError(fit_elman)
```

## Predicción Elman

```{r elman-pred}
# Realizar predicción
pred_elman <- predict(fit_elman, x_test)

# Desnormalizar resultados
pred_real_elman <- denormalize(pred_elman, y_vec)
actual_real <- y_vec[-train_idx]

# Graficar resultados
plot(actual_real, type="p", col="blue", pch=16,
     main="Predicción Elman vs Valor Real",
     xlab="Punto de prueba",
     ylab="Cantidad")
points(pred_real_elman, col="red", pch=16)
legend("topright", 
       legend=c("Valor Real", "Predicción"),
       col=c("blue", "red"),
       pch=16)

# Calcular error (asegurando dimensiones correctas)
rmse_elman <- sqrt(mean((as.vector(actual_real) - as.vector(pred_real_elman))^2))
print(paste("RMSE Elman:", rmse_elman))
```

## Red Neuronal Jordan

```{r jordan-model}
# Entrenamiento del modelo Jordan
fit_jordan <- jordan(x = x_train, 
                    y = y_train,
                    size = c(3),
                    learnFuncParams = c(0.1),
                    maxit = 500)

# Mostrar error de entrenamiento
plotIterativeError(fit_jordan)
```

## Predicción Jordan

```{r jordan-pred}
# Realizar predicción
pred_jordan <- predict(fit_jordan, x_test)

# Desnormalizar resultados
pred_real_jordan <- denormalize(pred_jordan, y_vec)

# Graficar resultados
plot(actual_real, type="p", col="blue", pch=16,
     main="Predicción Jordan vs Valor Real",
     xlab="Punto de prueba",
     ylab="Cantidad")
points(pred_real_jordan, col="red", pch=16)
legend("topright", 
       legend=c("Valor Real", "Predicción"),
       col=c("blue", "red"),
       pch=16)

# Calcular error (asegurando dimensiones correctas)
rmse_jordan <- sqrt(mean((as.vector(actual_real) - as.vector(pred_real_jordan))^2))
print(paste("RMSE Jordan:", rmse_jordan))
```

## Comparación de Modelos

```{r compare-models}
# Crear dataframe con resultados
results <- data.frame(
  Modelo = c("Elman", "Jordan"),
  RMSE = c(rmse_elman, rmse_jordan)
)

# Mostrar resultados
print("Comparación de modelos:")
print(results)
```

## Conclusiones

El análisis muestra que:

1. Los datos contienen 13 meses de ventas (Dic 2010 - Dic 2011)
2. Se utilizaron 3 lags para la predicción
3. Se compararon dos tipos de redes neuronales recurrentes:
   - Red Elman: utiliza retroalimentación de la capa oculta
   - Red Jordan: utiliza retroalimentación de la capa de salida
4. Los resultados muestran la capacidad de ambos modelos para capturar patrones en las ventas mensuales

La comparación de RMSE nos permite determinar cuál modelo tuvo mejor desempeño en este conjunto de datos particular.
